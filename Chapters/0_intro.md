# Introduction

Depression represents one of the most significant public health challenges of the 21st century, affecting millions of individuals worldwide and contributing to substantial personal, social, and economic burdens. Early detection of depression is of paramount importance, as timely intervention has been shown to improve treatment outcomes, reduce the risk of chronicity, and mitigate the severe consequences associated with untreated depressive episodes, including impaired functioning and increased risk of suicide. Despite the critical need for early identification, current diagnostic practices often fall short in providing scalable and accessible solutions that can reach the broader population.

The Patient Health Questionnaire-8 (PHQ-8) has emerged as the most widely adopted instrument for the early detection and screening of depression in both clinical and community settings. The PHQ-8 is a self-administered, multiple-choice questionnaire that assesses the frequency of core depressive symptoms over the preceding two weeks. Its simplicity, brevity, and ease of administration have contributed to its widespread use as a standard tool for depression screening. However, while the PHQ-8 offers a practical and efficient means of identifying individuals at risk, it is inherently limited by its reliance on self-reported symptoms and its inability to capture the rich contextual and behavioral information that often accompanies depressive states.

A fundamental shortcoming of the PHQ-8 lies in its exclusive focus on subjective symptom reporting, which can be influenced by factors such as stigma, lack of insight, or social desirability bias. Moreover, the questionnaire format is inherently constrained in its capacity to capture non-verbal indicators of depression, such as changes in vocal tone, speech patterns, and facial expressions. These behavioral and affective cues, which are routinely assessed during clinical interviews, provide valuable information about an individual's emotional state and may reveal depressive symptoms that are not explicitly articulated in self-report measures. Consequently, there is a pressing need for more comprehensive and objective approaches to early depression detection that can supplement or enhance the information provided by traditional questionnaires.

Recent advances in machine learning (ML) and multimodal data analysis offer promising avenues for addressing these limitations. By integrating information from multiple behavioral modalities—including textual content, vocal characteristics, and facial expressions—multimodal ML systems have the potential to capture a broader spectrum of depression-relevant indicators. Such systems can analyze not only what is said, but also how it is said and expressed, thereby providing a richer and more nuanced assessment of mental health status. The scalability and automation afforded by ML approaches further enhance their suitability for large-scale screening and continuous monitoring applications, potentially bridging the gap between clinical assessment and real-world deployment.

The core experiment presented in this work is grounded in the hypothesis that a multimodal machine learning approach can serve as a scalable and effective method for early depression detection, surpassing the limitations of traditional questionnaire-based screening. The central thesis posits that by leveraging complementary information from textual, audio, and visual modalities, it is possible to achieve predictive performance that matches or exceeds the accuracy of the PHQ-8 questionnaire. This hypothesis is motivated by the recognition that depression manifests across multiple behavioral channels, and that the integration of these channels can provide a more comprehensive and objective assessment than any single modality alone.

To empirically evaluate this thesis, the study implements a multimodal ML system that integrates linguistic features from interview transcripts, acoustic features from speech recordings, and facial expression features from video data. The effectiveness of this system is assessed by comparing its classification accuracy to that of the PHQ-8 questionnaire, with a target benchmark of achieving an accuracy equal to or greater than 80%—the established performance level of the PHQ-8 in clinical screening contexts. Success in this experiment would demonstrate the viability of multimodal ML approaches as practical tools for early depression detection, with the potential to enhance current screening practices and improve mental health outcomes on a population scale.

In summary, this work seeks to explore the possibility of utilizing machine learning systems to supplement and aid in early depression detection through multimodal analysis. By systematically comparing a multimodal ML system with the PHQ-8 questionnaire, the study examines whether integrating behavioral and contextual information could enhance current depression screening approaches. The findings of this research may provide insights into how machine learning could complement existing mental health assessment tools to support more comprehensive and accessible screening methods.
