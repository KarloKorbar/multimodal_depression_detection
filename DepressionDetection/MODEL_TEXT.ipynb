{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac8bbbf",
   "metadata": {},
   "source": [
    "### data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7660d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.loader import ResultsLoader, TextLoader, AudioLoader, FaceLoader\n",
    "\n",
    "# Initialize loaders\n",
    "results_loader = ResultsLoader()\n",
    "text_loader = TextLoader() \n",
    "audio_loader = AudioLoader()\n",
    "face_loader = FaceLoader()\n",
    "\n",
    "# Get balanced subset of data (100% of total data)\n",
    "percentage = 0\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results data\n",
    "df_result = results_loader.get_data(percentage=percentage, random_state=random_state)\n",
    "# Load text features\n",
    "df_text = text_loader.get_data(percentage=percentage, random_state=random_state)\n",
    "\n",
    "display(df_text)    \n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346544992608171",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8656a9b4c579587b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:13.801936Z",
     "start_time": "2024-11-02T20:55:13.480830Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df_text['TRANSCRIPT_text'] = df_text['TRANSCRIPT_text'].apply(text_preprocessing)\n",
    "\n",
    "display(df_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735288116a3d855d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d711d6498b3253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:14.621402Z",
     "start_time": "2024-11-02T20:55:13.881165Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Word Cloud for the text data\n",
    "text = \" \".join(df_text['TRANSCRIPT_text'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18521861ec34ba4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:14.785871Z",
     "start_time": "2024-11-02T20:55:14.624016Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Length of words\n",
    "X_train_lengths = df_text['TRANSCRIPT_text'].apply(len)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(X_train_lengths, kde=True)\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.xlabel('Length of Text')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a954a238517513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:15.238857Z",
     "start_time": "2024-11-02T20:55:14.786564Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Most common tokens\n",
    "nltk.download('punkt')\n",
    "all_tokens = nltk.word_tokenize(text)\n",
    "common_tokens = Counter(all_tokens).most_common(20)\n",
    "\n",
    "tokens_df = pd.DataFrame(common_tokens, columns=['Token', 'Count'])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=tokens_df, x='Token', y='Count')\n",
    "plt.title('Most Common Tokens')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b12f8f9a641db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f426afa82b1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:15.243667Z",
     "start_time": "2024-11-02T20:55:15.239491Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.merge(df_text, df_result, on=\"ID\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['TRANSCRIPT_text'], df['PHQ_Binary'], test_size=0.2,random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431e6dd857b04d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### pipeline & hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072276b9b87ed49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:20.588376Z",
     "start_time": "2024-11-02T20:55:15.245957Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with TF-IDF and a classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), stop_words='english')),  # Using bigrams\n",
    "    ('clf', RandomForestClassifier(random_state=rand_seed))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning using Grid Search\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.75, 1.0],\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbad1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After grid search training\n",
    "# Save the best model\n",
    "import joblib\n",
    "joblib.dump(grid_search.best_estimator_, 'text_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd05bd66f351b0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8071649a43a36d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:20.694630Z",
     "start_time": "2024-11-02T20:55:20.612972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "# Debug: Check the shapes and types of y_pred\n",
    "print(f'y_pred: {y_pred}')\n",
    "print(f'y_test: {y_test}')\n",
    "\n",
    "# Generate and display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=grid_search.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_search.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
