{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac8bbbf",
   "metadata": {},
   "source": [
    "# Text-based Depression Detection Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7660d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Tuple\n",
    "\n",
    "import joblib\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from preprocessing.loader_results import ResultsLoader\n",
    "from preprocessing.loader_text import TextLoader\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#Constants\n",
    "RANDOM_SEED = 42\n",
    "DATA_PERCENTAGE = 0  # 100% of the data\n",
    "FIGURE_SIZE = (15, 8)\n",
    "\n",
    "# Hyperparameter tuning using Grid Search\n",
    "PARAM_GRID = {\n",
    "    'tfidf__max_df': [0.75, 1.0],\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [None, 10, 20]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c9a49bed254b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72a3a44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:45:12.238034Z",
     "start_time": "2025-04-17T14:45:12.063477Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_PERCENTAGE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(percentage: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mDATA_PERCENTAGE\u001b[49m, random_state: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m RANDOM_SEED) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m df_result, df_text\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Initialize loader\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATA_PERCENTAGE' is not defined"
     ]
    }
   ],
   "source": [
    "def load_data(percentage: float = DATA_PERCENTAGE, random_state: int = RANDOM_SEED) -> Tuple[\n",
    "    pd.DataFrame, pd.DataFrame]:\n",
    "    # Initialize loaders\n",
    "    results_loader = ResultsLoader()\n",
    "    text_loader = TextLoader()\n",
    "\n",
    "    # Load data\n",
    "    df_result = results_loader.get_data(percentage=percentage, random_state=random_state)\n",
    "    df_text = text_loader.get_data(percentage=percentage, random_state=random_state)\n",
    "\n",
    "    return df_text, df_result\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df_text, df_result = load_data()\n",
    "\n",
    "# Display data\n",
    "print(\"Text Features:\")\n",
    "display(df_text)\n",
    "print(\"\\nReslutls:\")\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346544992608171",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8656a9b4c579587b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:13.801936Z",
     "start_time": "2024-11-02T20:55:13.480830Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def text_preprocessing(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "df_text['TRANSCRIPT_text'] = df_text['TRANSCRIPT_text'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735288116a3d855d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d711d6498b3253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:14.621402Z",
     "start_time": "2024-11-02T20:55:13.881165Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_wordcloud():\n",
    "    # Word Cloud for the text data\n",
    "    global text, wordcloud\n",
    "    text = \" \".join(df_text['TRANSCRIPT_text'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=FIGURE_SIZE)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_length_of_words():\n",
    "    # Length of words\n",
    "    X_train_lengths = df_text['TRANSCRIPT_text'].apply(len)\n",
    "    plt.figure(figsize=FIGURE_SIZE)\n",
    "    sns.histplot(X_train_lengths, kde=True)\n",
    "    plt.title('Distribution of Text Lengths')\n",
    "    plt.xlabel('Length of Text')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_most_common_tokens():\n",
    "    # Most common tokens\n",
    "    all_tokens = nltk.word_tokenize(text)\n",
    "    common_tokens = Counter(all_tokens).most_common(20)\n",
    "    tokens_df = pd.DataFrame(common_tokens, columns=['Token', 'Count'])\n",
    "    plt.figure(figsize=FIGURE_SIZE)\n",
    "    sns.barplot(data=tokens_df, x='Token', y='Count')\n",
    "    plt.title('Most Common Tokens')\n",
    "    plt.xlabel('Token')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_wordcloud()\n",
    "plot_length_of_words()\n",
    "plot_most_common_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b12f8f9a641db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f426afa82b1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:15.243667Z",
     "start_time": "2024-11-02T20:55:15.239491Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.merge(df_text, df_result, on=\"ID\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['TRANSCRIPT_text'], df['PHQ_Binary'], test_size=0.2,\n",
    "                                                    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431e6dd857b04d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pipeline & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072276b9b87ed49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:20.588376Z",
     "start_time": "2024-11-02T20:55:15.245957Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a pipeline with TF-IDF and a classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), stop_words='english')),  # Using bigrams\n",
    "    ('clf', RandomForestClassifier(random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, PARAM_GRID, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd05bd66f351b0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8071649a43a36d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T20:55:20.694630Z",
     "start_time": "2024-11-02T20:55:20.612972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "# Debug: Check the shapes and types of y_pred\n",
    "print(f'y_pred: {y_pred}')\n",
    "print(f'y_test: {y_test}')\n",
    "\n",
    "# Generate and display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=grid_search.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_search.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5fc525ee059662",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "4bbad1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(grid_search.best_estimator_, 'text_model.joblib')\n",
    "print('Model saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
