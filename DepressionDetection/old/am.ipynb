{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T12:32:50.551450Z",
     "start_time": "2024-07-30T12:32:50.548671Z"
    }
   },
   "id": "5172898583cfb6e7",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0,0,0,0,0,0,0,0,0,0,0,-9.3103,2.0175,0.22462,0.22488,-0.10969,0.038833,0.135,0.4781,-0.006263,-0.21851,-0.30289,0.13218,0.11002,0.07417,0.036744,0.070742,-0.014848,-0.09472,0.032859,0.032926,0.036399,0.00094644,-0.015,0.10935,-0.028545,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
      "0  0,0,0,0,0,0,0,0,0,0,0,-9.2498,2.0553,-0.049655...                                                                                                                                                                                                                                                                     \n",
      "1  0,0,0,0,0,0,0,-0.30805,0,0,0,-8.8736,2.1421,-0...                                                                                                                                                                                                                                                                     \n",
      "2  0,0,0,0,0,0,0,-0.30553,0,0,0,-8.8355,2.2538,-0...                                                                                                                                                                                                                                                                     \n",
      "3  0,0,0,0,0,0,0,-0.32064,0,0,0,-8.9991,2.0058,-0...                                                                                                                                                                                                                                                                     \n",
      "4  162,0,0,0,0,0,0,-0.31298,0.8872,0.62305,0,-9.3...                                                                                                                                                                                                                                                                     \n",
      "   753.36,2405.3,3081.5,3865.9,4280.8\n",
      "0  812.41,2203.2,3121.1,3598.4,4116.2\n",
      "1     827.9,2176.6,3047.9,3523,4095.6\n",
      "2  832.05,2090.4,2807.2,3303.3,4184.8\n",
      "3    882.31,2097.5,2636.9,3078,4321.1\n",
      "4    906.89,2121.7,2756.5,3352,4438.4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Time'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/7z/vthwfhrj4038flrlbnclw7tw0000gn/T/ipykernel_74965/4037833234.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlibrosa\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/College/Diplomski/Code/multimodal_depression_detection/DepressionDetection/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[1;32m    166\u001B[0m             \u001B[0mvalidate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidate\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m             \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m         )\n\u001B[1;32m    169\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m         op = _MergeOperation(\n\u001B[0m\u001B[1;32m    171\u001B[0m             \u001B[0mleft_df\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m             \u001B[0mright_df\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m             \u001B[0mhow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhow\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/College/Diplomski/Code/multimodal_depression_detection/DepressionDetection/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001B[0m\n\u001B[1;32m    790\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mright_join_keys\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    791\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    792\u001B[0m             \u001B[0mleft_drop\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    793\u001B[0m             \u001B[0mright_drop\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 794\u001B[0;31m         ) = self._get_merge_keys()\n\u001B[0m\u001B[1;32m    795\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    796\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mleft_drop\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    797\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleft\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_drop_labels_or_levels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mleft_drop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/College/Diplomski/Code/multimodal_depression_detection/DepressionDetection/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1293\u001B[0m                         \u001B[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1294\u001B[0m                         \u001B[0;31m#  the latter of which will raise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m                         \u001B[0mrk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mHashable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1296\u001B[0m                         \u001B[0;32mif\u001B[0m \u001B[0mrk\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1297\u001B[0;31m                             \u001B[0mright_keys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mright\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_label_or_level_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1298\u001B[0m                         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1299\u001B[0m                             \u001B[0;31m# work-around for merge_asof(right_index=True)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1300\u001B[0m                             \u001B[0mright_keys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mright\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/College/Diplomski/Code/multimodal_depression_detection/DepressionDetection/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1907\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mother_axes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1908\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_level_reference\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1909\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_level_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1910\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1911\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1912\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1913\u001B[0m         \u001B[0;31m# Check for duplicates\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1914\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Time'"
     ]
    }
   ],
   "source": [
    "def preprocess_audio(path):\n",
    "    covarep_df = pd.read_csv('data_audio/300_COVAREP.csv', delimiter='\\t')\n",
    "    formant_df = pd.read_csv('data_audio/300_FORMANT.csv', delimiter='\\t')\n",
    "    \n",
    "    # Check the contents of the CSV files\n",
    "    print (covarep_df.head())\n",
    "    print (formant_df.head())\n",
    "    \n",
    "    # Combine the CSV files\n",
    "    data_df = pd.merge(covarep_df, formant_df, on='Time')\n",
    "    \n",
    "    return data_df\n",
    "def preprocess_all_audio(path):\n",
    "     for filename in os.listdir(path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            try:\n",
    "                label = int(filename.split('_')[0])\n",
    "            except ValueError:\n",
    "                continue  # Skip files that don't follow the naming convention\n",
    "            transcript = preprocess_transcript(file_path)\n",
    "            data['label'].append(label)\n",
    "            data['transcript'].append(transcript)\n",
    "\n",
    "def audio_preprocess(path):\n",
    "# Load the CSV files\n",
    "\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "#print(data_df.isnull().sum())\n",
    "\n",
    "# Handle missing values (e.g., fill with mean)\n",
    "data_df.fillna(data_df.mean(), inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "data_df_scaled = pd.DataFrame(scaler.fit_transform(data_df), columns=data_df.columns)\n",
    "\n",
    "#print(data_df_scaled.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T12:59:25.226486Z",
     "start_time": "2024-07-30T12:59:24.914761Z"
    }
   },
   "id": "b788f9d782e18b6c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/7z/vthwfhrj4038flrlbnclw7tw0000gn/T/ipykernel_74965/3149705378.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0;31m# Load the CSV files\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0mcovarep_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'data_audio/300_COVAREP.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0mformant_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'data_audio/300_FORMANT.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/College/Diplomski/Code/multimodal_depression_detection/DepressionDetection/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[1;32m    166\u001B[0m             \u001B[0mvalidate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidate\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m             \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m         )\n\u001B[1;32m    169\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m         op = _MergeOperation(\n\u001B[0m\u001B[1;32m    171\u001B[0m             \u001B[0mleft_df\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m             \u001B[0mright_df\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m             \u001B[0mhow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhow\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/College/Diplomski/Code/multimodal_depression_detection/DepressionDetection/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001B[0m\n\u001B[1;32m    790\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mright_join_keys\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    791\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    792\u001B[0m             \u001B[0mleft_drop\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    793\u001B[0m             \u001B[0mright_drop\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 794\u001B[0;31m         ) = self._get_merge_keys()\n\u001B[0m\u001B[1;32m    795\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    796\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mleft_drop\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    797\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleft\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_drop_labels_or_levels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mleft_drop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/College/Diplomski/Code/multimodal_depression_detection/DepressionDetection/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1293\u001B[0m                         \u001B[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1294\u001B[0m                         \u001B[0;31m#  the latter of which will raise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m                         \u001B[0mrk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mHashable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1296\u001B[0m                         \u001B[0;32mif\u001B[0m \u001B[0mrk\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1297\u001B[0;31m                             \u001B[0mright_keys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mright\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_label_or_level_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1298\u001B[0m                         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1299\u001B[0m                             \u001B[0;31m# work-around for merge_asof(right_index=True)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1300\u001B[0m                             \u001B[0mright_keys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mright\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/College/Diplomski/Code/multimodal_depression_detection/DepressionDetection/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1907\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mother_axes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1908\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_level_reference\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1909\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_level_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1910\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1911\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1912\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1913\u001B[0m         \u001B[0;31m# Check for duplicates\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1914\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'time'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the CSV files\n",
    "covarep_df = pd.read_csv('data_audio/300_COVAREP.csv')\n",
    "formant_df = pd.read_csv('data_audio/300_FORMANT.csv')\n",
    "\n",
    "# Check the contents of the CSV files\n",
    "covarep_df.head()\n",
    "formant_df.head()\n",
    "\n",
    "# Combine the CSV files\n",
    "data_df = pd.merge(covarep_df, formant_df, on='time')\n",
    "\n",
    "# Check for missing values\n",
    "print(data_df.isnull().sum())\n",
    "\n",
    "# Handle missing values (e.g., fill with mean)\n",
    "data_df.fillna(data_df.mean(), inplace=True)\n",
    "\n",
    "# Assuming the label is in a column called 'label' (this will need to be adjusted based on actual data)\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "data_df_scaled = pd.DataFrame(scaler.fit_transform(data_df.drop(columns=['label'])), columns=data_df.drop(columns=['label']).columns)\n",
    "data_df_scaled['label'] = data_df['label']\n",
    "\n",
    "print(data_df_scaled.head())\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "# Basic statistics\n",
    "print(data_df.describe())\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data_df.corr(), annot=True, fmt='.2f')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of features\n",
    "data_df.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()\n",
    "\n",
    "# Train Test Split\n",
    "X = data_df_scaled.drop(columns=['label'])\n",
    "y = data_df_scaled['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating the Pipeline & Hyperparameter Tuning\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# Perform Grid Search CV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluation, Classification Report & Confusion Matrix\n",
    "# Predict on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T12:32:53.149007Z",
     "start_time": "2024-07-30T12:32:52.925441Z"
    }
   },
   "id": "4119de05f1ff4297",
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
